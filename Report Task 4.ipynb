{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uwUA_58FApQ"
   },
   "source": [
    "**CC7221:** Reconocimiento Visual con Deep Learning\n",
    "\n",
    "**Prof:** José M. Saavedra Rondo \n",
    "\n",
    "**Teacher Assistants:** Pablo Torres, Cristóbal Loyola \n",
    "\n",
    "**Members:** Humberto Rodrigues, David Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVZUwHuvFF8N"
   },
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QX8cFApwFZI4"
   },
   "source": [
    "La segmentación de imágenes es uno de los campos de la visión por computadora que ha visto grandes avances en los últimos tiempos, impulsado por sus diversos usos, desde carros con sistemas de conducción automatizado, hasta software de monitoreo de multitudes. En este trabajo se abordará el modelo `DeepLab` con la finalidad de detectar espermatozoides humanos en una imagen y las distintas partes que lo componen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8hniTu5FIhm"
   },
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMQb_DqUfbY2"
   },
   "source": [
    "El dataset original utilizado para este problema constaba de 14 imágenes para train y 6 para test, por cada imagen se tenía una máscara correspondiente a cada parte del espermatozoide (cabeza, cuerpo y cola).\n",
    "\n",
    "Al tener tan pocos elementos este dataset, fue necesario usar técnicas de `data augmentation`, tras las cuales se obtuvo un dataset total de train de 1665 imgenes y 444 imágenes para test, ambas con sus respectivas máscaras.\n",
    "\n",
    "Una vez completada la generación del dataset a utilizar se procedió a la construcción de los modelos utilizando `pytorch`.\n",
    "\n",
    "El problema a resolver es un problema de Clasificación con 4 clases `['__background__', 'head', 'body', 'tail']."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekuW0_QhFLWR"
   },
   "source": [
    "# Desarrollo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTVd5uZ8hz7m"
   },
   "source": [
    "## Manejo de Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrEqVgSbh4PB"
   },
   "source": [
    "Como se mencionó anteriormente se utilizaron técnicas de `data augmentation` para incrementar el volumen de datos para ambos datasets a utilizar. Particularmente se aplicaron las siguientes transformaciones sobre las imágenes y máscaras originales para así obtener nuevas instancias de representación.\n",
    "\n",
    "1. Las imágenes originales fueron rotadas hasta los 180° en sentido antihorario, usando pasos de 5°\n",
    "2. Se aplicó un flip horizontal a las imágenes originales y luego todo el paso `1`\n",
    "3. Se aplicó un flip vertical a las imágenes originales y luego todo el paso `1`\n",
    "\n",
    "En cuanto al tamaño de las imágenes a ambas se le aplicó un resize de `(580x780)`. Durante los experimentos que utilizaron un `backbone` preentrenado, las imágenes a color fueron normalizadas utilizando `mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]` debido a que `pytorch` así lo amerita a la hora de utilizar sus modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g29_CIrzg2PH"
   },
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1xfWe2fg7V_"
   },
   "source": [
    "El modelo utilizado fue [DeeplabV3](https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/), este modelo tiene principalmente dos componentes:\n",
    "\n",
    "- Un backbone ResNet (en este caso ResNet-50)\n",
    "\n",
    "- Un clasificador (Head) con el número de clases que se esperan predecir\n",
    "\n",
    "Nuestros experimentos se basaron en utilizar versiones preentrenadas o no de dicho backbone, mientras que los pesos del clasificador siempre eran aprendidos desde cero, de acuerdo al número de clases que amerita este problema.\n",
    "\n",
    "Cabe destacar que los modelos preentrenados utilizaron el dataset `COCO train2017` con 20 clases presentes en el `PASCAL VOC dataset`. El objetivo de esto es comprobar si existe conocimiento que pueda ayudar a solucionar el problema de segmentación de imágenes a pesar de que estos fueron entrenados en un contexto distinto y compararlos con modelos con pesos limpios que aprendan directamente del contexto de nuestro problema actual.\n",
    "\n",
    "En esta sección vamos a mostrar los cuatro experimentos principales que se realizaron. Ciertos parámetros en común para los experimentos fueron:\n",
    "\n",
    "- optimizador: `AdamW` con un `learn_rate=1e-3`\n",
    "\n",
    "- loss: `CrossEntropyLoss`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Y0KNPXcFM-3"
   },
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOaQL5oFIYik"
   },
   "source": [
    "## Experimento 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fqDIJlujZQ6"
   },
   "source": [
    "En este exprimento se utilizó el backbone preentrenado, las imágenes se normalizaron, se utilizó un `batch_size=10` y `epochs=25`. Debido al tamaño de las imágenes nos fue imposible contemplar `batch_size` de mayor tamaño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBmnw8qjm0as"
   },
   "source": [
    "### Gráfico de la Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![report_imgs/ex1_loss.png](report_imgs/ex1_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRgWbDRal31P"
   },
   "source": [
    "### Valores promedio obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQWWB8cLn_Xx"
   },
   "source": [
    "loss: 0.07586 | IoU: 0.31242 | Dice: 0.02615"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "155cAWYZnwqQ"
   },
   "source": [
    "### Algunos ejemplos de lo obtenido\n",
    "Máscaras de background, head, body y tail en ese orden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![report_imgs/ex1.png](report_imgs/ex1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbsfC5nnIfap"
   },
   "source": [
    "## Experimento 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este exprimento se utilizó el backbone sin preentrenar, las imágenes no se normalizaron, se utilizó un `batch_size=10` y `epochs=25`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de la Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![report_imgs/ex2_loss.png](report_imgs/ex2_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores promedio obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss: 0.35263 | IoU: 0.00000 | Dice: 0.02491"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algunos ejemplos de lo obtenido\n",
    "Máscaras de background, head, body y tail en ese orden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![report_imgs/ex2.png](report_imgs/ex2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este exprimento se utilizó el backbone preentrenado, las imágenes se normalizaron, se utilizó un `batch_size=5` y `epochs=10`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de la Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores promedio obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss: 0.07198 | IoU: 0.32160 | Dice: 0.02613"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algunos ejemplos de lo obtenido\n",
    "Máscaras de background, head, body y tail en ese orden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![report_imgs/ex3.png](report_imgs/ex3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este exprimento se utilizó el backbone sin preentrenar, las imágenes no se normalizaron, se utilizó un `batch_size=5` y `epochs=10`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de la Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores promedio obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss: 0.81401 | IoU: 0.00000 | Dice: 0.02474"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algunos ejemplos de lo obtenido\n",
    "Máscaras de background, head, body y tail en ese orden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![report_imgs/ex4.png](report_imgs/ex4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otros Experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicional a los elementos mostrados en los experimentos anteriores, se realizó otro conjunto de experimentos variando los siguientes aspectos:\n",
    "\n",
    "- Modelo preentrenado **sin** utilizar imágenes normalizadas\n",
    "\n",
    "- Resize de imágenes a (600x600), seguido de un centerCrop(400x400)\n",
    "\n",
    "- Usar un compound Loss definido como `(0.8 * CrossEntropyLoss) + (0.2 * DiceLoss)`\n",
    "\n",
    "- Usar optimizador `Adadelta` con `learn_rate=1e-4`\n",
    "\n",
    "Estos resultados no fueron mostrados en detalle, debido a que no ofrecian una mejora significativa, adicionalmente tenían problemas para representar las clases con poca densidad de pixeles (`tails`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones y Análisis de Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basándonos en los resultados obtenidos de nuestros exprimentos, podemos concluir lo siguiente:\n",
    "\n",
    "- Existe información que resuelve el problema de segmentación de imágenes en los backbone de los modelos preentrenados (al menos en `pytorch`) incluso si estos fueron entrenados usando un contexto distinto a aquiel con el que se esta probando\n",
    "\n",
    "- Si bien en los modelos \"limpios\" no se obtienen buenos resultados, se puede apreciar en el modelo de 25 épocas que empiezan a aparecer detecciones de segmentos dentro de las imágenes, por lo que se puede concluir que con un volumen de datos superior y un mayor tiempo de entrenamiento se podría llegar a lograr un conocimiento similar al que se encuentra en los modelos preentrenados.\n",
    "\n",
    "- CrossEntropyLoss, por si sola no parece ser la función de loss más adecuada para este problema, si bien es una de las más comunmente utilizadas. Esto debido a los bajos valores que se obtienen para la función de loss en base a otras métricas (iou o diceLoss).\n",
    "\n",
    "- Finalmente, el enfoque de utilizar `batch_size=5` y `epochs=10` dan resultados bastante similares a su homólogo `batch_size=10` y `epochs=25`, en considerablemente menos tiempo de entrenamiento (~50%).\n",
    "\n",
    "Como trabajo futuro se plantea una comparativa entre los otros dos modelos ofrecidos por `pytorch` para la segmentación de imágenes que son FCN-50, LR-ASPP.\n",
    "\n",
    "\n",
    "Todos los experimentos, código fuente y manipulación de la data utilizado para esta tarea se encuentra en este [repositorio](https://github.com/davidrojas0791/VR_DL_4)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "WVZUwHuvFF8N",
    "i8hniTu5FIhm"
   ],
   "name": "Report Task 4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
